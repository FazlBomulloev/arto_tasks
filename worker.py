import asyncio
import logging
import time
import json
import random
from typing import Dict, List, Optional
from collections import deque
from telethon import TelegramClient
from telethon.sessions import StringSession
from telethon.errors import FloodWaitError, RPCError, AuthKeyInvalidError
from telethon.tl.functions.messages import GetMessagesViewsRequest
from telethon.tl.functions.channels import JoinChannelRequest

from config import find_lang_code, API_ID, API_HASH, read_setting, REDIS_HOST, REDIS_PORT, REDIS_PASSWORD
from database import (
    init_db_pool, shutdown_db_pool, update_account_status,
    increment_account_fails, reset_account_fails, 
    get_ban_accounts_for_retry, mark_account_retry_attempt
)
from exceptions import SessionError, RateLimitError
from redis import Redis

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - [WORKER] - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/worker.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger('worker')

class MixedBatchWorker:
    def __init__(self):
        self.redis_client = None
        self.running = False
        self.max_retries = 3
        self.restart_count = 0
        self.max_restarts = 10
        
        # –ö—ç—à –Ω–∞—Å—Ç—Ä–æ–µ–∫
        self.cached_settings = {}
        self.last_settings_update = 0
        
        # –£–ü–†–û–©–ï–ù–ù–´–ï —Å—á–µ—Ç—á–∏–∫–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Å–æ–≥–ª–∞—Å–Ω–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º
        current_time = time.time()
        self.performance_stats = {
            'start_time': current_time,
            
            # –°—á–µ—Ç—á–∏–∫–∏ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Å—Ä–µ–¥–Ω–µ–≥–æ –∑–∞ —Å–µ–∫—É–Ω–¥—É (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 60 –º–∏–Ω—É—Ç)
            'tasks_last_minute': deque(maxlen=60),    # –ó–∞ –∫–∞–∂–¥—É—é –º–∏–Ω—É—Ç—É (60 –º–∏–Ω—É—Ç)
            
            # –°—á–µ—Ç—á–∏–∫–∏ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞) 
            'tasks_last_24h': deque(maxlen=1440),     # –ó–∞ –∫–∞–∂–¥—É—é –º–∏–Ω—É—Ç—É (24 —á–∞—Å–∞ = 1440 –º–∏–Ω—É—Ç)
            
            'last_minute_update': current_time,
            'tasks_current_minute': 0,
            'last_stats_save': current_time
        }
        
    async def start(self):
        """–ó–∞–ø—É—Å–∫ –≤–æ—Ä–∫–µ—Ä–∞ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ–º"""
        logger.info("üöÄ –ó–∞–ø—É—Å–∫ Mixed Batch Worker (–ø—Ä–æ—Å–º–æ—Ç—Ä—ã + –ø–æ–¥–ø–∏—Å–∫–∏ –≤ –æ–¥–Ω–æ–º –±–∞—Ç—á–µ)...")
        
        while self.restart_count < self.max_restarts:
            try:
                await self._initialize_connections()
                await self._run_main_cycle()
                break
                
            except KeyboardInterrupt:
                logger.info("‚èπÔ∏è –ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª –æ—Å—Ç–∞–Ω–æ–≤–∫–∏")
                break
                
            except Exception as e:
                self.restart_count += 1
                logger.error(f"üí• –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô –°–ë–û–ô #{self.restart_count}: {e}")
                
                if self.restart_count >= self.max_restarts:
                    logger.error(f"‚ùå –ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–æ–≤ ({self.max_restarts})")
                    break
                
                await self._handle_crash_recovery()
        
        await self._shutdown()
    
    async def _initialize_connections(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π"""
        try:
            await init_db_pool()
            logger.info("‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ–¥–∫–ª—é—á–µ–Ω–∞")
            
            if self.redis_client:
                try:
                    self.redis_client.close()
                except:
                    pass
                    
            self.redis_client = Redis(
                host=REDIS_HOST,
                port=REDIS_PORT,
                password=REDIS_PASSWORD,
                decode_responses=True,
                socket_connect_timeout=10,
                socket_timeout=10,
                retry_on_timeout=True,
                health_check_interval=30
            )
            
            self.redis_client.ping()
            logger.info("‚úÖ Redis –ø–æ–¥–∫–ª—é—á–µ–Ω")
            
            await self._update_cached_settings()
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
            raise
    
    async def _handle_crash_recovery(self):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –ø–æ—Å–ª–µ —Å–±–æ—è"""
        logger.warning(f"üîÑ –í–û–°–°–¢–ê–ù–û–í–õ–ï–ù–ò–ï –ü–û–°–õ–ï –°–ë–û–Ø #{self.restart_count}")
        
        try:
            await self._cleanup_connections()
            await self._clear_ready_tasks()
            
            logger.info("‚è≥ –ü–∞—É–∑–∞ 2 –º–∏–Ω—É—Ç—ã –¥–ª—è —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏ —Å–∏—Å—Ç–µ–º—ã...")
            await asyncio.sleep(120)
            
            self._reset_worker_state()
            logger.info(f"üîÑ –ì–æ—Ç–æ–≤ –∫ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫—É #{self.restart_count + 1}")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è: {e}")
            await asyncio.sleep(60)
    
    async def _cleanup_connections(self):
        """–û—á–∏—â–∞–µ—Ç —Å—Ç–∞—Ä—ã–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è"""
        try:
            if self.redis_client:
                self.redis_client.close()
                self.redis_client = None
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π: {e}")
    
    async def _clear_ready_tasks(self):
        """–£–¥–∞–ª—è–µ—Ç –≥–æ—Ç–æ–≤—ã–µ –∑–∞–¥–∞—á–∏ –∏–∑ Redis (–∏–∑–±–µ–≥–∞–µ–º –¥—É–±–ª–µ–π –ø—Ä–∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–µ)"""
        try:
            if not self.redis_client:
                return
                
            current_time = time.time()
            ready_tasks = self.redis_client.zrangebyscore(
                "task_queue", min=0, max=current_time, start=0, num=10000
            )
            
            if ready_tasks:
                for task_json in ready_tasks:
                    self.redis_client.zrem("task_queue", task_json)
                
                logger.warning(f"üóëÔ∏è –£–î–ê–õ–ï–ù–û {len(ready_tasks)} –≥–æ—Ç–æ–≤—ã—Ö –∑–∞–¥–∞—á –ø–æ—Å–ª–µ —Å–±–æ—è")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –≥–æ—Ç–æ–≤—ã—Ö –∑–∞–¥–∞—á: {e}")
    
    def _reset_worker_state(self):
        """–°–±—Ä–∞—Å—ã–≤–∞–µ—Ç –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –≤–æ—Ä–∫–µ—Ä–∞"""
        self.running = False
        current_time = time.time()
        self.performance_stats['last_minute_update'] = current_time
        self.performance_stats['last_stats_save'] = current_time
        self.performance_stats['tasks_current_minute'] = 0
        logger.info("üîÑ –°–æ—Å—Ç–æ—è–Ω–∏–µ –≤–æ—Ä–∫–µ—Ä–∞ —Å–±—Ä–æ—à–µ–Ω–æ")
    
    async def _update_cached_settings(self):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è —Å–º–µ—à–∞–Ω–Ω—ã—Ö –±–∞—Ç—á–µ–π"""
        try:
            self.cached_settings = {
                # –ù–û–í–´–ï –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤  
                'view_reading_time': read_setting('view_reading_time.txt', 5.0),         # X2
                'view_connection_pause': read_setting('view_connection_pause.txt', 3.0), # X1
                
                # –ù–û–í–´–ï –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–º–µ—à–∞–Ω–Ω—ã—Ö –±–∞—Ç—á–µ–π
                'mixed_batch_size': int(read_setting('mixed_batch_size.txt', 500.0)),
                'mixed_batch_pause': read_setting('mixed_batch_pause.txt', 30.0),
                
                # –°—Ç–∞—Ä—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
                'view_period': read_setting('followPeriod.txt', 3.0) * 3600,
                'sub_lag': read_setting('lag.txt', 14.0) * 60,
                'sub_range': read_setting('range.txt', 5.0) * 60,
                'timeout_count': int(read_setting('timeout_count.txt', 3.0)),
                'timeout_duration': read_setting('timeout_duration.txt', 13.0) * 60,
                'accounts_delay': read_setting('accounts_delay.txt', 2.0) * 60
            }
            
            self.last_settings_update = time.time()
            
            logger.info(f"""
‚öôÔ∏è –ù–ê–°–¢–†–û–ô–ö–ò MIXED BATCH –í–û–†–ö–ï–†–ê –û–ë–ù–û–í–õ–ï–ù–´:
   üì¶ –°–ú–ï–®–ê–ù–ù–´–ï –ë–ê–¢–ß–ò:
   üìä –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {self.cached_settings['mixed_batch_size']} –∑–∞–¥–∞—á (–ª—é–±—ã—Ö —Ç–∏–ø–æ–≤)
   ‚è∏Ô∏è –ü–∞—É–∑–∞ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏: {self.cached_settings['mixed_batch_pause']} —Å–µ–∫
   
   üëÄ –ü–ê–†–ê–ú–ï–¢–†–´ –ü–†–û–°–ú–û–¢–†–û–í:
   üìñ –í—Ä–µ–º—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞: {self.cached_settings['view_reading_time']} —Å–µ–∫ (X2)
   üîå –ü–∞—É–∑–∞ –ø–æ–¥–∫–ª—é—á/–≤—ã–∫–ª: {self.cached_settings['view_connection_pause']} —Å–µ–∫ (X1)
   
   üì∫ –ü–û–î–ü–ò–°–ö–ò:
   üìÖ –ë–∞–∑–æ–≤–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞: {self.cached_settings['sub_lag']/60:.1f} –º–∏–Ω
   üé≤ –†–∞–∑–±—Ä–æ—Å: {self.cached_settings['sub_range']/60:.1f} –º–∏–Ω
            """)
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫: {e}")
    
    async def _run_main_cycle(self):
        """–ó–∞–ø—É—Å–∫ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ —Å —Å–º–µ—à–∞–Ω–Ω—ã–º–∏ –±–∞—Ç—á–∞–º–∏"""
        logger.info("üîÑ –ó–∞–ø—É—Å–∫ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ —Å –°–ú–ï–®–ê–ù–ù–´–ú–ò –±–∞—Ç—á–∞–º–∏")
        
        self.running = True
        last_ban_check = time.time()
        last_cleanup = time.time()
        last_stats_save = time.time()
        cycle_count = 0
        
        if cycle_count == 0:
            self.restart_count = 0
        
        while self.running:
            try:
                cycle_count += 1
                current_time = time.time()
                
                await self._process_worker_commands()
                
                if current_time - self.last_settings_update > 300:
                    await self._update_cached_settings()
                
                if current_time - last_stats_save > 60:
                    await self._save_simplified_stats_to_redis()
                    last_stats_save = current_time
                
                if current_time - last_ban_check > 3600:
                    await self._check_banned_accounts_for_retry()
                    last_ban_check = current_time
                
                if current_time - last_cleanup > 21600:
                    await self._cleanup_old_tasks()
                    last_cleanup = current_time
                
                # –ì–õ–ê–í–ù–ê–Ø –õ–û–ì–ò–ö–ê - –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å–º–µ—à–∞–Ω–Ω—ã—Ö –±–∞—Ç—á–µ–π
                processed_in_cycle = await self._process_mixed_batch()
                
                await self._process_retry_tasks()
                
                if cycle_count % 100 == 0:
                    await self._log_simple_stats()
                
                # –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –ø–∞—É–∑–∞
                if processed_in_cycle > 0:
                    pause_time = random.uniform(10, 20)
                else:
                    pause_time = random.uniform(30, 60)
                    
                if cycle_count % 50 == 0:
                    queue_size = self.redis_client.zcard("task_queue") or 0
                    ready_count = self.redis_client.zcount("task_queue", 0, current_time) or 0
                    logger.info(f"üíì –¶–∏–∫–ª #{cycle_count} | –û—á–µ—Ä–µ–¥—å: {queue_size} | –ì–æ—Ç–æ–≤—ã—Ö: {ready_count}")
                    
                await asyncio.sleep(pause_time)
                
            except KeyboardInterrupt:
                logger.info("‚èπÔ∏è –ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª –æ—Å—Ç–∞–Ω–æ–≤–∫–∏")
                self.running = False
                break
                
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ —Ü–∏–∫–ª–µ #{cycle_count}: {e}")
                await asyncio.sleep(30)
                
                if cycle_count > 0 and cycle_count % 10 == 0:
                    logger.warning("üîÑ –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –æ—à–∏–±–æ–∫, –∏–Ω–∏—Ü–∏–∏—Ä—É—é –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫")
                    raise Exception("Too many consecutive errors")
    
    async def _process_mixed_batch(self) -> int:
        """
        –ì–õ–ê–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å–º–µ—à–∞–Ω–Ω—ã–π –±–∞—Ç—á (–ø—Ä–æ—Å–º–æ—Ç—Ä—ã + –ø–æ–¥–ø–∏—Å–∫–∏ –≤–º–µ—Å—Ç–µ)
        """
        current_time = time.time()
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º –≥–æ—Ç–æ–≤—ã–µ –∑–∞–¥–∞—á–∏ –õ–Æ–ë–´–• —Ç–∏–ø–æ–≤ –¥–æ –ª–∏–º–∏—Ç–∞ –±–∞—Ç—á–∞
            mixed_tasks = await self._get_ready_mixed_tasks(current_time)
            
            if not mixed_tasks:
                return 0
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –±–∞—Ç—á–∞
            view_count = sum(1 for task in mixed_tasks if task.get('task_type') == 'view')
            subscribe_count = sum(1 for task in mixed_tasks if task.get('task_type') == 'subscribe')
            total_count = len(mixed_tasks)
            
            batch_start_time = time.time()
            logger.info(f"""
üì¶ –û–ë–†–ê–ë–ê–¢–´–í–ê–Æ –°–ú–ï–®–ê–ù–ù–´–ô –ë–ê–¢–ß:
   üìä –í—Å–µ–≥–æ –∑–∞–¥–∞—á: {total_count}
   üëÄ –ü—Ä–æ—Å–º–æ—Ç—Ä–æ–≤: {view_count}
   üì∫ –ü–æ–¥–ø–∏—Å–æ–∫: {subscribe_count}
            """)
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –í–°–ï –∑–∞–¥–∞—á–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ (—Å–º–µ—à–∞–Ω–Ω–æ)
            results = await self._execute_mixed_tasks_parallel(mixed_tasks)
            
            batch_duration = time.time() - batch_start_time
            success_count = sum(1 for r in results if r is True)
            success_rate = (success_count / total_count) * 100 if total_count > 0 else 0
            
            logger.info(f"""
‚úÖ –°–ú–ï–®–ê–ù–ù–´–ô –ë–ê–¢–ß –ó–ê–í–ï–†–®–ï–ù:
   ‚è±Ô∏è –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {batch_duration:.1f}—Å
   üìä –£—Å–ø–µ—à–Ω–æ—Å—Ç—å: {success_count}/{total_count} ({success_rate:.1f}%)
            """)
            
            # –ü–∞—É–∑–∞ –º–µ–∂–¥—É —Å–º–µ—à–∞–Ω–Ω—ã–º–∏ –±–∞—Ç—á–∞–º–∏
            batch_pause = self.cached_settings['mixed_batch_pause']
            if total_count > 300:  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –ø–∞—É–∑—É –¥–ª—è –±–æ–ª—å—à–∏—Ö –±–∞—Ç—á–µ–π
                batch_pause *= 1.2
                
            logger.info(f"‚è∏Ô∏è –ü–∞—É–∑–∞ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏: {batch_pause:.1f} —Å–µ–∫")
            await asyncio.sleep(batch_pause)
            
            return len(results)
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–º–µ—à–∞–Ω–Ω–æ–≥–æ –±–∞—Ç—á–∞: {e}")
            return 0
    
    async def _get_ready_mixed_tasks(self, current_time: float) -> List[Dict]:
        """–ü–æ–ª—É—á–∞–µ—Ç –≥–æ—Ç–æ–≤—ã–µ –∑–∞–¥–∞—á–∏ –õ–Æ–ë–´–• —Ç–∏–ø–æ–≤ –¥–ª—è —Å–º–µ—à–∞–Ω–Ω–æ–≥–æ –±–∞—Ç—á–∞"""
        try:
            batch_size = self.cached_settings['mixed_batch_size']
            
            # –ü–æ–ª—É—á–∞–µ–º –≥–æ—Ç–æ–≤—ã–µ –∑–∞–¥–∞—á–∏ –∏–∑ Redis (–õ–Æ–ë–´–ï —Ç–∏–ø—ã)
            ready_tasks_data = self.redis_client.zrangebyscore(
                "task_queue",
                min=0,
                max=current_time,
                withscores=True,
                start=0,
                num=batch_size  # –ë–µ—Ä–µ–º —Ä–æ–≤–Ω–æ —Å—Ç–æ–ª—å–∫–æ, —Å–∫–æ–ª—å–∫–æ –Ω—É–∂–Ω–æ –¥–ª—è –±–∞—Ç—á–∞
            )
            
            if not ready_tasks_data:
                return []
            
            mixed_tasks = []
            removed_broken_tasks = 0
            
            for task_json, score in ready_tasks_data:
                try:
                    task_data = json.loads(task_json)
                    
                    # –ü—Ä–∏–Ω–∏–º–∞–µ–º –õ–Æ–ë–´–ï —Ç–∏–ø—ã –∑–∞–¥–∞—á
                    task_type = task_data.get('task_type')
                    if task_type in ['view', 'subscribe']:
                        task_data['redis_key'] = task_json
                        mixed_tasks.append(task_data)
                    else:
                        logger.warning(f"‚ö†Ô∏è –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –∑–∞–¥–∞—á–∏: {task_type}")
                        self.redis_client.zrem("task_queue", task_json)
                        removed_broken_tasks += 1
                        
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∑–∞–¥–∞—á–∏: {e}")
                    self.redis_client.zrem("task_queue", task_json)
                    removed_broken_tasks += 1
            
            if removed_broken_tasks > 0:
                logger.warning(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–æ {removed_broken_tasks} –±–∏—Ç—ã—Ö –∑–∞–¥–∞—á")
            
            # –£–¥–∞–ª—è–µ–º –≤–∑—è—Ç—ã–µ –∑–∞–¥–∞—á–∏ –∏–∑ Redis
            for task in mixed_tasks:
                self.redis_client.zrem("task_queue", task['redis_key'])
                del task['redis_key']
            
            return mixed_tasks
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–º–µ—à–∞–Ω–Ω—ã—Ö –∑–∞–¥–∞—á: {e}")
            return []
    
    async def _execute_mixed_tasks_parallel(self, tasks: List[Dict]) -> List[bool]:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç —Å–º–µ—à–∞–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ"""
        if not tasks:
            return []
        
        try:
            # –°–æ–∑–¥–∞–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –∑–∞–¥–∞—á–∏ –¥–ª—è –í–°–ï–• —Ç–∏–ø–æ–≤
            parallel_tasks = []
            
            for task in tasks:
                task_type = task.get('task_type')
                
                if task_type == 'view':
                    # –ü—Ä–æ—Å–º–æ—Ç—Ä—ã —Å –Ω–æ–≤–æ–π –ª–æ–≥–∏–∫–æ–π: –ü–æ–¥–∫–ª—é—á–∏–ª—Å—è ‚Üí –ü–∞—É–∑–∞ X1 ‚Üí –ü—Ä–æ—Å–º–æ—Ç—Ä X2 ‚Üí –ü–∞—É–∑–∞ X1 ‚Üí –û—Ç–∫–ª—é—á–∏–ª—Å—è
                    parallel_task = asyncio.create_task(
                        self._execute_single_view_task_new_logic(task)
                    )
                elif task_type == 'subscribe':
                    # –ü–æ–¥–ø–∏—Å–∫–∏ –∫–∞–∫ –æ–±—ã—á–Ω–æ
                    parallel_task = asyncio.create_task(
                        self._execute_single_subscribe_task(task)
                    )
                else:
                    logger.warning(f"‚ö†Ô∏è –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –∑–∞–¥–∞—á–∏: {task_type}")
                    continue
                
                parallel_tasks.append(parallel_task)
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –í–°–ï –∑–∞–¥–∞—á–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
            results = await asyncio.gather(*parallel_tasks, return_exceptions=True)
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            success_count = 0
            error_count = 0
            view_success = 0
            subscribe_success = 0
            
            for i, result in enumerate(results):
                task = tasks[i]
                phone = task.get('phone', 'unknown')
                channel = task.get('channel', 'unknown')
                task_type = task.get('task_type', 'unknown')
                
                if isinstance(result, Exception):
                    error_count += 1
                    logger.error(f"üí• {task_type.upper()} | {phone} | @{channel} | {result}")
                elif result:
                    success_count += 1
                    if task_type == 'view':
                        view_success += 1
                    elif task_type == 'subscribe':
                        subscribe_success += 1
                    logger.debug(f"‚úÖ {task_type.upper()} | {phone} | @{channel}")
                else:
                    error_count += 1
                    logger.warning(f"‚ùå {task_type.upper()} | {phone} | @{channel}")
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —É–ø—Ä–æ—â–µ–Ω–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            self._update_simplified_time_stats(success_count)
            
            logger.info(f"üìä –°–ú–ï–®–ê–ù–ù–´–ô –†–ï–ó–£–õ–¨–¢–ê–¢: üëÄ{view_success} üì∫{subscribe_success} ‚ùå{error_count}")
            
            return [r for r in results if not isinstance(r, Exception)]
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Å–º–µ—à–∞–Ω–Ω—ã—Ö –∑–∞–¥–∞—á: {e}")
            return []
    
    async def _execute_single_view_task_new_logic(self, task: Dict) -> bool:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –æ–¥–Ω—É –∑–∞–¥–∞—á—É –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Å –ù–û–í–û–ô –ª–æ–≥–∏–∫–æ–π:
        1. –ü–æ–¥–∫–ª—é—á–∏–ª—Å—è
        2. –ü–∞—É–∑–∞ X1 —Å–µ–∫ (view_connection_pause)
        3. –ü—Ä–æ—Å–º–æ—Ç—Ä X2 —Å–µ–∫ (view_reading_time)  
        4. –ü–∞—É–∑–∞ X1 —Å–µ–∫ (view_connection_pause)
        5. –û—Ç–∫–ª—é—á–∏–ª—Å—è
        """
        session_data = task.get('account_session', '')
        phone = task.get('phone', 'unknown')
        channel = task.get('channel', 'unknown')
        post_id = task.get('post_id', 0)
        
        if not session_data:
            logger.warning(f"‚ùå {phone}: –Ω–µ—Ç session_data")
            return False
        
        client = None
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫
            connection_pause = self.cached_settings['view_connection_pause']  # X1
            reading_time = self.cached_settings['view_reading_time']          # X2
            
            # 1. –ü–û–î–ö–õ–Æ–ß–ò–õ–°–Ø –∫ Telegram
            client = TelegramClient(
                StringSession(session_data),
                API_ID, API_HASH,
                lang_code=find_lang_code(task.get('lang', 'English')),
                connection_retries=1,
                timeout=20
            )
            
            await client.connect()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—é
            if not await client.is_user_authorized():
                logger.warning(f"‚ùå {phone}: –Ω–µ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω")
                await self._handle_task_failure(phone, 'view')
                return False
            
            # 2. –ü–ê–£–ó–ê X1 —Å–µ–∫—É–Ω–¥ (–ø–∞—É–∑–∞ –ø–æ—Å–ª–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è)
            await asyncio.sleep(connection_pause)            
            # –ü–æ–ª—É—á–∞–µ–º entity –∫–∞–Ω–∞–ª–∞ –∏ –≤—ã–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ—Å–º–æ—Ç—Ä
            channel_entity = await client.get_entity(channel)
            await client(GetMessagesViewsRequest(
                peer=channel_entity,
                id=[post_id],
                increment=True
            ))
            
            await asyncio.sleep(reading_time)
            
            # 4. –ü–ê–£–ó–ê X1 —Å–µ–∫—É–Ω–¥ (–ø–∞—É–∑–∞ –ø–µ—Ä–µ–¥ –æ—Ç–∫–ª—é—á–µ–Ω–∏–µ–º)
            await asyncio.sleep(connection_pause)
            await self._handle_task_success(phone)
            return True
            
        except FloodWaitError as e:
            logger.warning(f"‚è≥ {phone}: FloodWait {e.seconds}s")
            await self._add_to_retry_queue(task, delay=e.seconds)
            return False
            
        except (RPCError, AuthKeyInvalidError) as e:
            logger.warning(f"‚ùå {phone}: –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ - {e}")
            await self._handle_task_failure(phone, 'view')
            return False
            
        except Exception as e:
            logger.error(f"üí• {phone}: –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ - {e}")
            await self._handle_task_failure(phone, 'view')
            return False
            
        finally:
            # 5. –í–°–ï–ì–î–ê –æ—Ç–∫–ª—é—á–∞–µ–º—Å—è
            if client:
                try:
                    await client.disconnect()
                    logger.debug(f"üîå {phone}: –æ—Ç–∫–ª—é—á–∏–ª—Å—è")
                except Exception as e:
                    logger.debug(f"–û—à–∏–±–∫–∞ –æ—Ç–∫–ª—é—á–µ–Ω–∏—è –∫–ª–∏–µ–Ω—Ç–∞ {phone}: {e}")
    
    async def _execute_single_subscribe_task(self, task: Dict) -> bool:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –æ–¥–Ω—É –∑–∞–¥–∞—á—É –ø–æ–¥–ø–∏—Å–∫–∏ (–ª–æ–≥–∏–∫–∞ –Ω–µ –∏–∑–º–µ–Ω–∏–ª–∞—Å—å)"""
        session_data = task.get('account_session', '')
        phone = task.get('phone', 'unknown')
        channel = task.get('channel', 'unknown')
        
        if not session_data:
            return False
        
        client = None
        
        try:
            client = TelegramClient(
                StringSession(session_data),
                API_ID, API_HASH,
                lang_code=find_lang_code(task.get('lang', 'English')),
                connection_retries=1,
                timeout=20
            )
            
            await client.connect()
            
            if not await client.is_user_authorized():
                await self._handle_task_failure(phone, 'subscribe')
                return False
            
            channel_entity = await client.get_entity(channel)
            await client(JoinChannelRequest(channel_entity))
            
            await asyncio.sleep(random.uniform(2, 5))
            
            logger.debug(f"‚úÖ {phone}: –ø–æ–¥–ø–∏—Å–∞–Ω –Ω–∞ @{channel}")
            await self._handle_task_success(phone)
            return True
            
        except Exception as e:
            logger.warning(f"‚ùå {phone}: –æ—à–∏–±–∫–∞ –ø–æ–¥–ø–∏—Å–∫–∏ –Ω–∞ @{channel} - {e}")
            await self._handle_task_failure(phone, 'subscribe')
            return False
            
        finally:
            if client:
                try:
                    await client.disconnect()
                except:
                    pass
    
    def _update_simplified_time_stats(self, successful_tasks: int):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç —É–ø—Ä–æ—â–µ–Ω–Ω—É—é –≤—Ä–µ–º–µ–Ω–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
        current_time = time.time()
        
        # –î–æ–±–∞–≤–ª—è–µ–º —É—Å–ø–µ—à–Ω—ã–µ –∑–∞–¥–∞—á–∏ –∫ —Ç–µ–∫—É—â–µ–π –º–∏–Ω—É—Ç–µ
        self.performance_stats['tasks_current_minute'] += successful_tasks
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω—É–∂–Ω–æ –ª–∏ –æ–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –º–∏–Ω—É—Ç–∞–º
        if current_time - self.performance_stats['last_minute_update'] >= 60.0:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–¥–∞—á–∏ –∑–∞ –ø—Ä–æ—à–µ–¥—à—É—é –º–∏–Ω—É—Ç—É
            tasks_this_minute = self.performance_stats['tasks_current_minute']
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≤ –æ–±–µ –æ—á–µ—Ä–µ–¥–∏ (60 –º–∏–Ω—É—Ç –∏ 24 —á–∞—Å–∞)
            self.performance_stats['tasks_last_minute'].append(tasks_this_minute)
            self.performance_stats['tasks_last_24h'].append(tasks_this_minute)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–∞ –∏ —Å–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫
            self.performance_stats['last_minute_update'] = current_time
            self.performance_stats['tasks_current_minute'] = 0
            
            logger.debug(f"üìä –ó–∞ –ø–æ—Å–ª–µ–¥–Ω—é—é –º–∏–Ω—É—Ç—É –≤—ã–ø–æ–ª–Ω–µ–Ω–æ {tasks_this_minute} –∑–∞–¥–∞—á")
    
    async def _save_simplified_stats_to_redis(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —É–ø—Ä–æ—â–µ–Ω–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ Redis —Å–æ–≥–ª–∞—Å–Ω–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º"""
        try:
            current_time = time.time()
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 60 –º–∏–Ω—É—Ç (–¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Å—Ä–µ–¥–Ω–µ–≥–æ –∑–∞ —Å–µ–∫—É–Ω–¥—É)
            tasks_last_hour = sum(self.performance_stats['tasks_last_minute'])
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞ (–¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è)
            tasks_last_24h = sum(self.performance_stats['tasks_last_24h'])
            
            stats_data = {
                'timestamp': current_time,
                'tasks_last_hour': tasks_last_hour,      # –î–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Å—Ä–µ–¥–Ω–µ–≥–æ –∑–∞ —Å–µ–∫
                'tasks_last_24h': tasks_last_24h,        # –î–ª—è —Ä–∞—Å—á–µ—Ç–∞ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
                'uptime': current_time - self.performance_stats['start_time'],
                'restart_count': self.restart_count
            }
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ Redis —Å TTL 10 –º–∏–Ω—É—Ç
            self.redis_client.setex('worker_stats', 600, json.dumps(stats_data))
            
            logger.debug(f"üìä –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {tasks_last_hour}/—á–∞—Å, {tasks_last_24h}/24—á")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —É–ø—Ä–æ—â–µ–Ω–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤ Redis: {e}")
    
    # === –°–õ–£–ñ–ï–ë–ù–´–ï –ú–ï–¢–û–î–´ ===
    
    async def _handle_task_success(self, phone: str):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —É—Å–ø–µ—à–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏"""
        try:
            await reset_account_fails(phone)
            logger.debug(f"üîì {phone}: —Å–±—Ä–æ—à–µ–Ω —Å—á–µ—Ç—á–∏–∫ –æ—à–∏–±–æ–∫")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —É—Å–ø–µ—Ö–∞ –¥–ª—è {phone}: {e}")
    
    async def _handle_task_failure(self, phone: str, task_type: str):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–µ—É–¥–∞—á–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏"""
        try:
            fail_count = await increment_account_fails(phone)
            
            if fail_count >= 3:
                await update_account_status(phone, 'ban')
                logger.warning(f"üö´ {phone}: –ø–µ—Ä–µ–≤–µ–¥–µ–Ω –≤ BAN (–Ω–µ—É–¥–∞—á: {fail_count})")
            else:
                logger.debug(f"‚ö†Ô∏è {phone}: –Ω–µ—É–¥–∞—á–∞ {fail_count}/3 ({task_type})")
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–µ—É–¥–∞—á–∏ –¥–ª—è {phone}: {e}")
    
    async def _add_to_retry_queue(self, task: Dict, delay: int = 0):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –∑–∞–¥–∞—á—É –≤ –æ—á–µ—Ä–µ–¥—å –ø–æ–≤—Ç–æ—Ä–æ–≤"""
        try:
            task['retry_count'] = task.get('retry_count', 0) + 1
            task['retry_after'] = time.time() + delay + random.uniform(60, 300)
            
            if task['retry_count'] <= self.max_retries:
                self.redis_client.lpush('retry_tasks', json.dumps(task))
                logger.debug(f"üîÑ –ó–∞–¥–∞—á–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤ retry (–ø–æ–ø—ã—Ç–∫–∞ {task['retry_count']}/{self.max_retries})")
            else:
                logger.warning(f"‚ùå –ó–∞–¥–∞—á–∞ –æ—Ç–±—Ä–æ—à–µ–Ω–∞ –ø–æ—Å–ª–µ {self.max_retries} –ø–æ–ø—ã—Ç–æ–∫")
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ retry: {e}")
    
    async def _process_retry_tasks(self):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–∞–¥–∞—á–∏ –∏–∑ –æ—á–µ—Ä–µ–¥–∏ –ø–æ–≤—Ç–æ—Ä–æ–≤"""
        try:
            current_time = time.time()
            
            for _ in range(10):
                task_data = self.redis_client.rpop('retry_tasks')
                if not task_data:
                    break
                
                try:
                    task = json.loads(task_data)
                    
                    if task.get('retry_after', 0) <= current_time:
                        # –í—Ä–µ–º—è –ø—Ä–∏—à–ª–æ - –≤—ã–ø–æ–ª–Ω—è–µ–º
                        if task.get('task_type') == 'view':
                            success = await self._execute_single_view_task_new_logic(task)
                        else:
                            success = await self._execute_single_subscribe_task(task)
                            
                        if success:
                            logger.debug(f"‚úÖ Retry –∑–∞–¥–∞—á–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
                    else:
                        # –í—Ä–µ–º—è –µ—â–µ –Ω–µ –ø—Ä–∏—à–ª–æ - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≤ –æ—á–µ—Ä–µ–¥—å
                        self.redis_client.lpush('retry_tasks', task_data)
                        break
                        
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ retry: {e}")
                    continue
                    
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ retry –æ—á–µ—Ä–µ–¥–∏: {e}")
    
    async def _process_worker_commands(self):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∫–æ–º–∞–Ω–¥—ã –æ—Ç –±–æ—Ç–∞"""
        try:
            command_data = self.redis_client.rpop('worker_commands')
            if not command_data:
                return
                
            command = json.loads(command_data)
            
            if command['command'] == 'reload_settings':
                logger.info("üîÑ –ü–æ–ª—É—á–µ–Ω–∞ –∫–æ–º–∞–Ω–¥–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫")
                await self._update_cached_settings()
                logger.info("‚úÖ –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±–Ω–æ–≤–ª–µ–Ω—ã")
            elif command['command'] == 'cleanup_tasks':
                logger.info("üóëÔ∏è –ó–∞–ø—Ä–æ—Å –æ—á–∏—Å—Ç–∫–∏ —Å—Ç–∞—Ä—ã—Ö –∑–∞–¥–∞—á")
                await self._cleanup_old_tasks()
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–æ–º–∞–Ω–¥: {e}")
    
    async def _check_banned_accounts_for_retry(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∑–∞–±–∞–Ω–µ–Ω–Ω—ã–µ –∞–∫–∫–∞—É–Ω—Ç—ã —Ä–∞–∑ –≤ 120 —á–∞—Å–æ–≤"""
        try:
            ban_accounts = await get_ban_accounts_for_retry()
            
            if not ban_accounts:
                logger.info("üîç –ù–µ—Ç –∑–∞–±–∞–Ω–µ–Ω–Ω—ã—Ö –∞–∫–∫–∞—É–Ω—Ç–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏")
                return
            
            logger.info(f"üîç –ü—Ä–æ–≤–µ—Ä—è—é {len(ban_accounts)} –∑–∞–±–∞–Ω–µ–Ω–Ω—ã—Ö –∞–∫–∫–∞—É–Ω—Ç–æ–≤...")
            
            for account in ban_accounts[:5]:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ –±–æ–ª–µ–µ 5 –∑–∞ —Ä–∞–∑
                phone = account['phone_number']
                
                try:
                    await mark_account_retry_attempt(phone)
                    
                    test_task = {
                        'account_session': account['session_data'],
                        'phone': phone,
                        'channel': 'telegram',
                        'lang': account['lang'],
                        'task_type': 'subscribe'
                    }
                    
                    success = await self._execute_single_subscribe_task(test_task)
                    
                    if success:
                        logger.info(f"üîì {phone}: –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏–∑ –±–∞–Ω–∞!")
                    else:
                        logger.info(f"üö´ {phone}: –æ—Å—Ç–∞–µ—Ç—Å—è –≤ –±–∞–Ω–µ")
                        
                    await asyncio.sleep(random.uniform(30, 60))
                    
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∑–∞–±–∞–Ω–µ–Ω–Ω–æ–≥–æ –∞–∫–∫–∞—É–Ω—Ç–∞ {phone}: {e}")
                    
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∑–∞–±–∞–Ω–µ–Ω–Ω—ã—Ö –∞–∫–∫–∞—É–Ω—Ç–æ–≤: {e}")
    
    async def _cleanup_old_tasks(self):
        """–û—á–∏—â–∞–µ—Ç —Å—Ç–∞—Ä—ã–µ –∑–∞–¥–∞—á–∏ –∏–∑ Redis"""
        try:
            current_time = time.time()
            cutoff_time = current_time - (48 * 3600)  # 48 —á–∞—Å–æ–≤ –Ω–∞–∑–∞–¥
            
            # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –∑–∞–¥–∞—á–∏ –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–π –æ—á–µ—Ä–µ–¥–∏
            old_tasks = self.redis_client.zrangebyscore(
                "task_queue", 0, cutoff_time, start=0, num=1000
            )
            
            if old_tasks:
                for task_json in old_tasks:
                    self.redis_client.zrem("task_queue", task_json)
                    
                logger.info(f"üóëÔ∏è –û—á–∏—â–µ–Ω–æ {len(old_tasks)} —Å—Ç–∞—Ä—ã—Ö –∑–∞–¥–∞—á –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–π –æ—á–µ—Ä–µ–¥–∏")
            
            # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ retry –∑–∞–¥–∞—á–∏
            retry_tasks = self.redis_client.lrange('retry_tasks', 0, -1)
            cleaned_retry = 0
            
            for task_json in retry_tasks:
                try:
                    task = json.loads(task_json)
                    if task.get('created_at', 0) < cutoff_time:
                        self.redis_client.lrem('retry_tasks', 1, task_json)
                        cleaned_retry += 1
                except:
                    # –£–¥–∞–ª—è–µ–º –±–∏—Ç—ã–µ –∑–∞–¥–∞—á–∏
                    self.redis_client.lrem('retry_tasks', 1, task_json)
                    cleaned_retry += 1
            
            if cleaned_retry > 0:
                logger.info(f"üóëÔ∏è –û—á–∏—â–µ–Ω–æ {cleaned_retry} —Å—Ç–∞—Ä—ã—Ö retry –∑–∞–¥–∞—á")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ —Å—Ç–∞—Ä—ã—Ö –∑–∞–¥–∞—á: {e}")
    
    async def _log_simple_stats(self):
        """–õ–æ–≥–∏—Ä—É–µ—Ç —É–ø—Ä–æ—â–µ–Ω–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
        try:
            total_in_redis = self.redis_client.zcard("task_queue") or 0
            current_time = time.time()
            ready_in_redis = self.redis_client.zcount("task_queue", 0, current_time) or 0
            retry_count = self.redis_client.llen("retry_tasks") or 0
            
            # –£–ü–†–û–©–ï–ù–ù–ê–Ø —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–æ–≥–ª–∞—Å–Ω–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º
            tasks_last_hour = sum(self.performance_stats['tasks_last_minute'])
            tasks_last_24h = sum(self.performance_stats['tasks_last_24h'])
            
            # –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–¥–∞—á –∑–∞ —Å–µ–∫—É–Ω–¥—É (–∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 60 –º–∏–Ω—É—Ç / 3600 —Å–µ–∫—É–Ω–¥)
            avg_per_second = tasks_last_hour / 3600 if tasks_last_hour > 0 else 0
            
            # –û—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–æ—á–Ω–æ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è (–≤—Å–µ –∑–∞–¥–∞—á–∏ –∑–∞ 24—á / –∑–∞–¥–∞—á–∏ –∑–∞ 60–º–∏–Ω)
            if tasks_last_hour > 0:
                estimated_hours = tasks_last_24h / tasks_last_hour
            else:
                estimated_hours = 0
            
            uptime = current_time - self.performance_stats['start_time']
            
            logger.info(f"""
üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê MIXED BATCH –í–û–†–ö–ï–†–ê (10 –º–∏–Ω):
   
   üõ°Ô∏è –í–û–°–°–¢–ê–ù–û–í–õ–ï–ù–ò–ï:
   üîÑ –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫–æ–≤: {self.restart_count}/{self.max_restarts}
   ‚è∞ –í—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã: {uptime/3600:.1f} —á–∞—Å–æ–≤
   
   üì¶ –°–ú–ï–®–ê–ù–ù–´–ï –ë–ê–¢–ß–ò:
   üìä –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {self.cached_settings.get('mixed_batch_size', 500)} –∑–∞–¥–∞—á (–ª—é–±—ã—Ö —Ç–∏–ø–æ–≤)
   ‚è∏Ô∏è –ü–∞—É–∑–∞ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏: {self.cached_settings.get('mixed_batch_pause', 30)}—Å
   
   üìã –û–ß–ï–†–ï–î–¨:
   üìã –í—Å–µ–≥–æ –∑–∞–¥–∞—á: {total_in_redis}
   ‚úÖ –ì–æ—Ç–æ–≤—ã—Ö —Å–µ–π—á–∞—Å: {ready_in_redis}
   üîÑ Retry –∑–∞–¥–∞—á: {retry_count}
   
   ‚ö° –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–¨ (—Å–æ–≥–ª–∞—Å–Ω–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º):
   üìà –ó–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 60 –º–∏–Ω—É—Ç: {tasks_last_hour} –∑–∞–¥–∞—á
   üìà –ó–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞: {tasks_last_24h} –∑–∞–¥–∞—á
   ‚ö° –°—Ä–µ–¥–Ω–µ–µ –∑–∞–¥–∞—á/—Å–µ–∫: {avg_per_second:.2f}
   ‚è±Ô∏è –û—Ä–∏–µ–Ω—Ç. –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {estimated_hours:.1f}—á
   
   üëÄ –ù–ê–°–¢–†–û–ô–ö–ò –ü–†–û–°–ú–û–¢–†–û–í:
   üìñ –í—Ä–µ–º—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞: {self.cached_settings.get('view_reading_time', 5)}—Å (X2)
   üîå –ü–∞—É–∑–∞ –ø–æ–¥–∫–ª—é—á/–≤—ã–∫–ª: {self.cached_settings.get('view_connection_pause', 3)}—Å (X1)
   
   üïê –í—Ä–µ–º—è: {time.strftime('%H:%M:%S')}""")
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
    
    async def stop(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤–æ—Ä–∫–µ—Ä–∞"""
        logger.info("‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–∫–∞ mixed batch –≤–æ—Ä–∫–µ—Ä–∞...")
        self.running = False
    
    async def _shutdown(self):
        """–ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã"""
        logger.info("üîÑ –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã mixed batch –≤–æ—Ä–∫–µ—Ä–∞...")
        
        try:
            await self._save_simplified_stats_to_redis()
            
            total_uptime = time.time() - self.performance_stats['start_time']
            tasks_total = sum(self.performance_stats['tasks_last_24h'])
            
            logger.info(f"""
üìä –§–ò–ù–ê–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê MIXED BATCH –í–û–†–ö–ï–†–ê:
   ‚è∞ –û–±—â–µ–µ –≤—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã: {total_uptime/3600:.1f} —á–∞—Å–æ–≤
   üîÑ –í—Å–µ–≥–æ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–æ–≤: {self.restart_count}
   ‚úÖ –ó–∞–¥–∞—á –≤—ã–ø–æ–ª–Ω–µ–Ω–æ: {tasks_total}
   üì¶ –†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã: –°–º–µ—à–∞–Ω–Ω—ã–µ –±–∞—Ç—á–∏ (–ø—Ä–æ—Å–º–æ—Ç—Ä—ã + –ø–æ–¥–ø–∏—Å–∫–∏)
   üöÄ –°—Ä–µ–¥–Ω—è—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {tasks_total/(total_uptime/3600):.1f} –∑–∞–¥–∞—á/—á–∞—Å
            """)
            
            if self.redis_client:
                self.redis_client.close()
            
            await shutdown_db_pool()
            logger.info("‚úÖ Mixed batch –≤–æ—Ä–∫–µ—Ä –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏: {e}")

# –ê–ª–∏–∞—Å—ã –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
SimpleTaskWorker = MixedBatchWorker
EnhancedTaskWorker = MixedBatchWorker
ResilientTaskWorker = MixedBatchWorker

# –ó–∞–ø—É—Å–∫ –≤–æ—Ä–∫–µ—Ä–∞
async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è mixed batch –≤–æ—Ä–∫–µ—Ä–∞"""
    worker = MixedBatchWorker()
    
    try:
        await worker.start()
    except KeyboardInterrupt:
        logger.info("‚èπÔ∏è –ü–æ–ª—É—á–µ–Ω Ctrl+C, –∑–∞–≤–µ—Ä—à–∞–µ–º —Ä–∞–±–æ—Ç—É...")
    except Exception as e:
        logger.error(f"üí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
    finally:
        await worker.stop()

if __name__ == "__main__":
    try:
        import uvloop
        uvloop.install()
        logger.info("‚úÖ uvloop —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
    except ImportError:
        logger.info("‚ö†Ô∏è uvloop –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π event loop")
    
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ Mixed Batch Worker (–ø—Ä–æ—Å–º–æ—Ç—Ä—ã + –ø–æ–¥–ø–∏—Å–∫–∏ –≤ –æ–¥–Ω–æ–º –±–∞—Ç—á–µ)...")
    asyncio.run(main())