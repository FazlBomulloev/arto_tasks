import asyncio
import logging
import time
import json
import random
from typing import Dict, List, Optional
from collections import deque
from telethon import TelegramClient
from telethon.sessions import StringSession
from telethon.errors import FloodWaitError, RPCError, AuthKeyInvalidError
from telethon.tl.functions.messages import GetMessagesViewsRequest
from telethon.tl.functions.channels import JoinChannelRequest

from config import find_lang_code, API_ID, API_HASH, read_setting, REDIS_HOST, REDIS_PORT, REDIS_PASSWORD
from database import (
    init_db_pool, shutdown_db_pool, update_account_status,
    increment_account_fails, reset_account_fails, 
    get_ban_accounts_for_retry, mark_account_retry_attempt
)
from exceptions import SessionError, RateLimitError
from redis import Redis

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞ –¥–ª—è –≤–æ—Ä–∫–µ—Ä–∞
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - [WORKER] - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/worker.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger('worker')

class EnhancedTaskWorker:
    def __init__(self):
        self.redis_client = None
        self.running = False
        self.max_retries = 3
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞ (—Ç–µ–ø–µ—Ä—å –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º—ã–µ)
        self.parallel_limits = {
            'view': 100,       # –ë—É–¥–µ—Ç –æ–±–Ω–æ–≤–ª—è—Ç—å—Å—è –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫
            'subscribe': 10     # –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
        }
        
        # –ó–∞–¥–µ—Ä–∂–∫–∏ –º–µ–∂–¥—É –∑–∞–¥–∞—á–∞–º–∏
        self.task_delays = {
            'view': (1, 5),      # 1-5 —Å–µ–∫—É–Ω–¥ –º–µ–∂–¥—É –ø—Ä–æ—Å–º–æ—Ç—Ä–∞–º–∏
            'subscribe': (15, 45) # 15-45 —Å–µ–∫—É–Ω–¥ –º–µ–∂–¥—É –ø–æ–¥–ø–∏—Å–∫–∞–º–∏
        }
        
        # –ö—ç—à –Ω–∞—Å—Ç—Ä–æ–µ–∫ —Å –Ω–æ–≤—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –±–∞—Ç—á–µ–π
        self.cached_settings = {}
        self.last_settings_update = 0
        
        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ —Å—á–µ—Ç—á–∏–∫–∏ –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ (–û–ë–ù–û–í–õ–ï–ù–û)
        current_time = time.time()
        self.performance_stats = {
            'processed_tasks': 0,
            'success_count': 0,
            'error_count': 0,
            
            # –í—Ä–µ–º–µ–Ω–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ (–û–ë–ù–û–í–õ–ï–ù–û)
            'tasks_last_minute': deque(maxlen=60),  # –ó–∞–¥–∞—á–∏ –∑–∞ –∫–∞–∂–¥—É—é —Å–µ–∫—É–Ω–¥—É
            'tasks_last_hour': deque(maxlen=60),    # –ó–∞–¥–∞—á–∏ –∑–∞ –∫–∞–∂–¥—É—é –º–∏–Ω—É—Ç—É
            'tasks_per_second': deque(maxlen=60),   # –ù–û–í–û–ï - –∑–∞–¥–∞—á–∏ –∑–∞ –∫–∞–∂–¥—É—é —Å–µ–∫—É–Ω–¥—É
            'last_minute_update': current_time,
            'last_hour_update': current_time,
            'last_second_update': current_time,     # –ù–û–í–û–ï
            
            # –°—á–µ—Ç—á–∏–∫–∏ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Å—Ä–µ–¥–Ω–∏—Ö (–ù–û–í–û–ï)
            'total_tasks_executed': 0,              # –ù–û–í–û–ï - –æ–±—â–∏–π —Å—á–µ—Ç—á–∏–∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö –∑–∞–¥–∞—á
            'start_time': current_time,             # –ù–û–í–û–ï - –≤—Ä–µ–º—è –∑–∞–ø—É—Å–∫–∞ –≤–æ—Ä–∫–µ—Ä–∞
            'last_stats_save': current_time,        # –ù–û–í–û–ï - –≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            'tasks_this_period': 0,                 # –ù–û–í–û–ï - –∑–∞–¥–∞—á–∏ –∑–∞ —Ç–µ–∫—É—â–∏–π –ø–µ—Ä–∏–æ–¥
            
            # –ë–∞—Ç—á —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            'batches_processed': 0,
            'avg_batch_size': 0,
            'last_batch_times': deque(maxlen=10),
            
            # –°—á–µ—Ç—á–∏–∫–∏ –ø–æ —Ç–∏–ø–∞–º –∑–∞–¥–∞—á
            'view_tasks_executed': 0,
            'subscribe_tasks_executed': 0,
            'total_execution_time': 0
        }
        
    async def start(self):
        logger.info("üöÄ –ó–∞–ø—É—Å–∫ Enhanced Task Worker —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π...")
        
        try:
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ë–î
            await init_db_pool()
            logger.info("‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ–¥–∫–ª—é—á–µ–Ω–∞")
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Redis
            self.redis_client = Redis(
                host=REDIS_HOST,
                port=REDIS_PORT,
                password=REDIS_PASSWORD,
                decode_responses=True
            )
            logger.info("‚úÖ Redis –ø–æ–¥–∫–ª—é—á–µ–Ω")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
            await self._update_cached_settings()
            
            # –ó–∞–ø—É—Å–∫ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ü–∏–∫–ª–∞
            self.running = True
            await self._main_loop()
            
        except Exception as e:
            logger.error(f"üí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤–æ—Ä–∫–µ—Ä–∞: {e}")
            raise
        finally:
            await self._shutdown()
    
    async def _update_cached_settings(self):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤–∫–ª—é—á–∞—è –Ω–æ–≤—ã–µ –±–∞—Ç—á –ø–∞—Ä–∞–º–µ—Ç—Ä—ã"""
        try:
            self.cached_settings = {
                'view_period': read_setting('followPeriod.txt', 3.0) * 3600,
                'view_delay': read_setting('delay.txt', 20.0) * 60,
                'sub_lag': read_setting('lag.txt', 14.0) * 60,
                'sub_range': read_setting('range.txt', 5.0) * 60,
                'timeout_count': int(read_setting('timeout_count.txt', 3.0)),
                'timeout_duration': read_setting('timeout_duration.txt', 13.0) * 60,
                
                # –ù–æ–≤—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –±–∞—Ç—á–µ–π
                'view_batch_size': int(read_setting('view_batch_size.txt', 100.0)),
                'view_batch_delay': read_setting('view_batch_delay.txt', 30.0),
                'subscribe_batch_delay': read_setting('subscribe_batch_delay.txt', 60.0),
                'accounts_delay': read_setting('accounts_delay.txt', 2.0) * 60
            }
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –ª–∏–º–∏—Ç—ã –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞
            self.parallel_limits['view'] = self.cached_settings['view_batch_size']
            
            self.last_settings_update = time.time()
            
            logger.info(f"""
‚öôÔ∏è –ù–ê–°–¢–†–û–ô–ö–ò ENHANCED –í–û–†–ö–ï–†–ê –û–ë–ù–û–í–õ–ï–ù–´:
   üëÄ –ü–µ—Ä–∏–æ–¥ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤: {self.cached_settings['view_period']/3600:.1f} —á–∞—Å–æ–≤
   üì¶ –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤: {self.cached_settings['view_batch_size']}
   ‚è≥ –ó–∞–¥–µ—Ä–∂–∫–∞ –±–∞—Ç—á–∞ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤: {self.cached_settings['view_batch_delay']} —Å–µ–∫
   ‚è≥ –ó–∞–¥–µ—Ä–∂–∫–∞ –±–∞—Ç—á–∞ –ø–æ–¥–ø–∏—Å–æ–∫: {self.cached_settings['subscribe_batch_delay']} —Å–µ–∫
   üì∫ –ë–∞–∑–æ–≤–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –ø–æ–¥–ø–∏—Å–æ–∫: {self.cached_settings['sub_lag']/60:.1f} –º–∏–Ω
   üé≤ –†–∞–∑–±—Ä–æ—Å –ø–æ–¥–ø–∏—Å–æ–∫: {self.cached_settings['sub_range']/60:.1f} –º–∏–Ω
   üî¢ –ü–æ–¥–ø–∏—Å–æ–∫ –¥–æ –ø–∞—É–∑—ã: {self.cached_settings['timeout_count']}
   ‚è∏Ô∏è –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–∞—É–∑—ã: {self.cached_settings['timeout_duration']/60:.1f} –º–∏–Ω
   ‚è∞ –ó–∞–¥–µ—Ä–∂–∫–∞ –∞–∫–∫–∞—É–Ω—Ç–æ–≤: {self.cached_settings['accounts_delay']/60:.1f} –º–∏–Ω
            """)
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫: {e}")
    
    async def _save_stats_to_redis(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤–æ—Ä–∫–µ—Ä–∞ –≤ Redis –¥–ª—è –∞–¥–º–∏–Ω –ø–∞–Ω–µ–ª–∏"""
        try:
            current_time = time.time()
            
            # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏
            uptime = current_time - self.performance_stats['start_time']
            total_executed = self.performance_stats['total_tasks_executed']
            
            avg_per_minute = (total_executed / (uptime / 60)) if uptime > 60 else 0
            avg_per_second = (total_executed / uptime) if uptime > 0 else 0
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ –ø–µ—Ä–∏–æ–¥—ã
            tasks_last_minute = sum(self.performance_stats['tasks_per_second'])
            tasks_last_hour = sum(self.performance_stats['tasks_last_minute'])
            tasks_last_5min = self.performance_stats['tasks_this_period']  # –ó–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 5 –º–∏–Ω—É—Ç
            
            # –£—Å–ø–µ—à–Ω–æ—Å—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
            success_rate = 0.0
            if self.performance_stats['processed_tasks'] > 0:
                success_rate = (self.performance_stats['success_count'] / self.performance_stats['processed_tasks']) * 100
            
            stats_data = {
                'timestamp': current_time,
                'tasks_last_minute': tasks_last_minute,
                'tasks_last_5min': tasks_last_5min,
                'tasks_last_hour': tasks_last_hour,
                'avg_tasks_per_minute': avg_per_minute,
                'avg_tasks_per_second': avg_per_second,
                'total_executed': total_executed,
                'success_rate': success_rate,
                'view_tasks': self.performance_stats['view_tasks_executed'],
                'subscribe_tasks': self.performance_stats['subscribe_tasks_executed'],
                'batches_processed': self.performance_stats['batches_processed'],
                'uptime': uptime,
                'error_count': self.performance_stats['error_count']
            }
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ Redis —Å TTL 10 –º–∏–Ω—É—Ç
            self.redis_client.setex(
                'worker_stats', 
                600,  # 10 –º–∏–Ω—É—Ç TTL
                json.dumps(stats_data)
            )
            
            logger.debug(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ Redis: {tasks_last_minute} –∑–∞–¥–∞—á/–º–∏–Ω, —É—Å–ø–µ—à–Ω–æ—Å—Ç—å {success_rate:.1f}%")
            
            # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ —Ç–µ–∫—É—â–µ–≥–æ –ø–µ—Ä–∏–æ–¥–∞
            self.performance_stats['tasks_this_period'] = 0
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤ Redis: {e}")
    
    def _update_time_based_stats(self):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É (–û–ë–ù–û–í–õ–ï–ù–û)"""
        current_time = time.time()
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Å–µ–∫—É–Ω–¥–∞–º (–û–ë–ù–û–í–õ–ï–ù–û)
        if current_time - self.performance_stats['last_second_update'] >= 1.0:
            # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–¥–∞—á –∑–∞ –ø–æ—Å–ª–µ–¥–Ω—é—é —Å–µ–∫—É–Ω–¥—É
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É—Å–ø–µ—à–Ω–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω—é—é —Å–µ–∫—É–Ω–¥—É
            tasks_this_second = 0  # –ë—É–¥–µ—Ç –æ–±–Ω–æ–≤–ª—è—Ç—å—Å—è –≤ _execute_tasks_parallel
            
            self.performance_stats['tasks_per_second'].append(tasks_this_second)
            self.performance_stats['last_second_update'] = current_time
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –º–∏–Ω—É—Ç–∞–º (–û–ë–ù–û–í–õ–ï–ù–û)
        if current_time - self.performance_stats['last_minute_update'] >= 60.0:
            # –°—É–º–º–∏—Ä—É–µ–º –∑–∞–¥–∞—á–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω—é—é –º–∏–Ω—É—Ç—É
            tasks_this_minute = sum(self.performance_stats['tasks_per_second'])
            self.performance_stats['tasks_last_minute'].append(tasks_this_minute)
            self.performance_stats['last_minute_update'] = current_time
            
            # –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∑–∞ –º–∏–Ω—É—Ç—É
            logger.debug(f"üìä –ó–∞ –ø–æ—Å–ª–µ–¥–Ω—é—é –º–∏–Ω—É—Ç—É –≤—ã–ø–æ–ª–Ω–µ–Ω–æ {tasks_this_minute} –∑–∞–¥–∞—á")
            
            # –û—á–∏—â–∞–µ–º —Å—á–µ—Ç—á–∏–∫ —Å–µ–∫—É–Ω–¥ –¥–ª—è –Ω–æ–≤–æ–π –º–∏–Ω—É—Ç—ã
            self.performance_stats['tasks_per_second'] = deque(maxlen=60)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —á–∞—Å–∞–º
        if current_time - self.performance_stats['last_hour_update'] >= 3600.0:
            # –°—É–º–º–∏—Ä—É–µ–º –∑–∞–¥–∞—á–∏ –∑–∞ —á–∞—Å
            tasks_this_hour = sum(self.performance_stats['tasks_last_minute'])
            self.performance_stats['tasks_last_hour'].append(tasks_this_hour)
            self.performance_stats['last_hour_update'] = current_time
            
            logger.info(f"üìä –ó–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Å –≤—ã–ø–æ–ª–Ω–µ–Ω–æ {tasks_this_hour} –∑–∞–¥–∞—á")
    
    async def _main_loop(self):
        logger.info("üîÑ –ó–∞–ø—É—Å–∫ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ —Å –±–∞—Ç—á–µ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π")
        
        last_stats_time = time.time()
        last_ban_check = time.time()
        last_cleanup = time.time()
        last_stats_save = time.time()  # –ù–û–í–û–ï - –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        cycle_count = 0
        
        while self.running:
            try:
                cycle_count += 1
                current_time = time.time()
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                self._update_time_based_stats()
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–º–∞–Ω–¥—ã –æ—Ç –±–æ—Ç–∞
                await self._process_worker_commands()
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–∞–∂–¥—ã–µ 5 –º–∏–Ω—É—Ç
                if current_time - self.last_settings_update > 300:
                    await self._update_cached_settings()
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫–∞–∂–¥—É—é –º–∏–Ω—É—Ç—É (–ù–û–í–û–ï)
                if current_time - last_stats_save > 60:
                    await self._save_stats_to_redis()
                    last_stats_save = current_time
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–±–∞–Ω–µ–Ω–Ω—ã—Ö –∞–∫–∫–∞—É–Ω—Ç–æ–≤ (—Ä–∞–∑ –≤ —á–∞—Å)
                if current_time - last_ban_check > 3600:
                    await self._check_banned_accounts_for_retry()
                    last_ban_check = current_time
                
                # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –∑–∞–¥–∞—á (—Ä–∞–∑ –≤ 6 —á–∞—Å–æ–≤)
                if current_time - last_cleanup > 21600:
                    await self._cleanup_old_tasks()
                    last_cleanup = current_time
                
                # –û—Å–Ω–æ–≤–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–¥–∞—á —Å –±–∞—Ç—á–∞–º–∏
                processed_in_cycle = await self._process_ready_tasks_with_batches()
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º retry –∑–∞–¥–∞—á–∏
                await self._process_retry_tasks()
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–∞–∂–¥—ã–µ 5 –º–∏–Ω—É—Ç
                if current_time - last_stats_time > 300:
                    await self._log_enhanced_performance_stats()
                    self._reset_performance_counters()
                    last_stats_time = current_time
                
                # –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –ø–∞—É–∑–∞
                if processed_in_cycle > 0:
                    pause_time = random.uniform(10, 20)
                else:
                    pause_time = random.uniform(30, 60)
                    
                # –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç—É—Å –∫–∞–∂–¥—ã–µ 50 —Ü–∏–∫–ª–æ–≤
                if cycle_count % 50 == 0:
                    queue_size = self.redis_client.zcard("task_queue") or 0
                    ready_count = self.redis_client.zcount("task_queue", 0, current_time) or 0
                    logger.info(f"üíì –¶–∏–∫–ª #{cycle_count} | –û—á–µ—Ä–µ–¥—å: {queue_size} | –ì–æ—Ç–æ–≤—ã—Ö: {ready_count} | –í—ã–ø–æ–ª–Ω–µ–Ω–æ: {self.performance_stats['total_tasks_executed']}")
                    
                await asyncio.sleep(pause_time)
                
            except KeyboardInterrupt:
                logger.info("‚èπÔ∏è –ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª –æ—Å—Ç–∞–Ω–æ–≤–∫–∏")
                self.running = False
                break
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –≥–ª–∞–≤–Ω–æ–º —Ü–∏–∫–ª–µ: {e}")
                await asyncio.sleep(10)
    
    async def _process_ready_tasks_with_batches(self) -> int:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≥–æ—Ç–æ–≤—ã–µ –∑–∞–¥–∞—á–∏ –ø–∞–∫–µ—Ç–∞–º–∏ —Å –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º—ã–º–∏ –∑–∞–¥–µ—Ä–∂–∫–∞–º–∏"""
        current_time = time.time()
        total_processed = 0
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º –≥–æ—Ç–æ–≤—ã–µ –∑–∞–¥–∞—á–∏ –ø–æ —Ç–∏–ø–∞–º
            view_tasks = await self._get_ready_tasks_by_type('view', current_time)
            subscribe_tasks = await self._get_ready_tasks_by_type('subscribe', current_time)
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø—Ä–æ—Å–º–æ—Ç—Ä—ã –±–∞—Ç—á–∞–º–∏
            if view_tasks:
                batch_start_time = time.time()
                logger.info(f"üëÄ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –±–∞—Ç—á –∏–∑ {len(view_tasks)} –∑–∞–¥–∞—á –ø—Ä–æ—Å–º–æ—Ç—Ä–∞")
                
                view_results = await self._execute_tasks_parallel(view_tasks, 'view')
                total_processed += len(view_results)
                
                # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤—Ä–µ–º—è –±–∞—Ç—á–∞
                batch_duration = time.time() - batch_start_time
                self.performance_stats['last_batch_times'].append(batch_duration)
                self.performance_stats['batches_processed'] += 1
                self.performance_stats['total_execution_time'] += batch_duration
                
                # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤
                batch_delay = self.cached_settings['view_batch_delay']
                if len(view_tasks) > 50:  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∑–∞–¥–µ—Ä–∂–∫—É –¥–ª—è –±–æ–ª—å—à–∏—Ö –±–∞—Ç—á–µ–π
                    batch_delay *= 1.5
                    
                logger.info(f"‚è≥ –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤: {batch_delay:.1f} —Å–µ–∫")
                await asyncio.sleep(batch_delay)
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–æ–¥–ø–∏—Å–∫–∏ (—Å —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º —Ä–∞–∑–º–µ—Ä–æ–º –±–∞—Ç—á–∞ 5)
            if subscribe_tasks:
                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –ø–æ–¥–ø–∏—Å–æ–∫ –¥–æ 5
                subscribe_batch = subscribe_tasks[:5]
                
                batch_start_time = time.time()
                logger.info(f"üì∫ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –±–∞—Ç—á –∏–∑ {len(subscribe_batch)} –∑–∞–¥–∞—á –ø–æ–¥–ø–∏—Å–∫–∏")
                
                sub_results = await self._execute_tasks_parallel(subscribe_batch, 'subscribe')
                total_processed += len(sub_results)
                
                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏ –æ–±—Ä–∞—Ç–Ω–æ –≤ –æ—á–µ—Ä–µ–¥—å
                if len(subscribe_tasks) > 5:
                    remaining_tasks = subscribe_tasks[5:]
                    await self._return_tasks_to_queue(remaining_tasks)
                    logger.info(f"üîÑ –í–æ–∑–≤—Ä–∞—â–µ–Ω–æ {len(remaining_tasks)} –∑–∞–¥–∞—á –ø–æ–¥–ø–∏—Å–∫–∏ –≤ –æ—á–µ—Ä–µ–¥—å")
                
                # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏ –ø–æ–¥–ø–∏—Å–æ–∫
                batch_delay = self.cached_settings['subscribe_batch_delay']
                logger.info(f"‚è≥ –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏ –ø–æ–¥–ø–∏—Å–æ–∫: {batch_delay:.1f} —Å–µ–∫")
                await asyncio.sleep(batch_delay)
            
            return total_processed
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≥–æ—Ç–æ–≤—ã—Ö –∑–∞–¥–∞—á —Å –±–∞—Ç—á–∞–º–∏: {e}")
            return 0
    
    async def _return_tasks_to_queue(self, tasks: List[Dict]):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∑–∞–¥–∞—á–∏ –æ–±—Ä–∞—Ç–Ω–æ –≤ –æ—á–µ—Ä–µ–¥—å Redis"""
        try:
            tasks_data = {}
            current_time = time.time()
            
            for task in tasks:
                # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–±–æ–ª—å—à—É—é –∑–∞–¥–µ—Ä–∂–∫—É —á—Ç–æ–±—ã –∑–∞–¥–∞—á–∏ –Ω–µ –≤—ã–ø–æ–ª–Ω–∏–ª–∏—Å—å —Å—Ä–∞–∑—É
                new_execute_at = current_time + random.uniform(60, 300)  # 1-5 –º–∏–Ω—É—Ç
                task['execute_at'] = new_execute_at
                
                task_json = json.dumps(task)
                tasks_data[task_json] = new_execute_at
            
            if tasks_data:
                self.redis_client.zadd("task_queue", tasks_data)
                logger.debug(f"üîÑ –í–æ–∑–≤—Ä–∞—â–µ–Ω–æ {len(tasks)} –∑–∞–¥–∞—á –≤ –æ—á–µ—Ä–µ–¥—å")
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤–æ–∑–≤—Ä–∞—Ç–∞ –∑–∞–¥–∞—á –≤ –æ—á–µ—Ä–µ–¥—å: {e}")
    
    async def _get_ready_tasks_by_type(self, task_type: str, current_time: float) -> List[Dict]:
        """–ü–æ–ª—É—á–∞–µ—Ç –≥–æ—Ç–æ–≤—ã–µ –∑–∞–¥–∞—á–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ —Ç–∏–ø–∞ —Å —É—á–µ—Ç–æ–º –±–∞—Ç—á —Ä–∞–∑–º–µ—Ä–∞"""
        try:
            if task_type == 'view':
                limit = self.cached_settings['view_batch_size']
            elif task_type == 'subscribe':
                limit = 10  # –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ª–∏–º–∏—Ç –¥–ª—è –ø–æ–¥–ø–∏—Å–æ–∫, –Ω–æ –±–∞—Ç—á –±—É–¥–µ—Ç 5
            else:
                limit = 50
            
            # –ü–æ–ª—É—á–∞–µ–º –≥–æ—Ç–æ–≤—ã–µ –∑–∞–¥–∞—á–∏ –∏–∑ Redis
            ready_tasks_data = self.redis_client.zrangebyscore(
                "task_queue",
                min=0,
                max=current_time,
                withscores=True,
                start=0,
                num=limit * 2  # –ë–µ—Ä–µ–º —Å –∑–∞–ø–∞—Å–æ–º –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
            )
            
            if not ready_tasks_data:
                return []
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ —Ç–∏–ø—É –∑–∞–¥–∞—á
            filtered_tasks = []
            removed_broken_tasks = 0
            
            for task_json, score in ready_tasks_data:
                try:
                    task_data = json.loads(task_json)
                    if task_data.get('task_type') == task_type:
                        task_data['redis_key'] = task_json
                        filtered_tasks.append(task_data)
                        
                        if len(filtered_tasks) >= limit:
                            break
                            
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∑–∞–¥–∞—á–∏: {e}")
                    # –£–¥–∞–ª—è–µ–º –±–∏—Ç—É—é –∑–∞–¥–∞—á—É
                    self.redis_client.zrem("task_queue", task_json)
                    removed_broken_tasks += 1
            
            if removed_broken_tasks > 0:
                logger.warning(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–æ {removed_broken_tasks} –±–∏—Ç—ã—Ö –∑–∞–¥–∞—á –∏–∑ –æ—á–µ—Ä–µ–¥–∏")
            
            # –£–¥–∞–ª—è–µ–º –≤–∑—è—Ç—ã–µ –∑–∞–¥–∞—á–∏ –∏–∑ Redis
            for task in filtered_tasks:
                self.redis_client.zrem("task_queue", task['redis_key'])
                del task['redis_key']
            
            return filtered_tasks
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∑–∞–¥–∞—á —Ç–∏–ø–∞ {task_type}: {e}")
            return []
    
    async def _execute_tasks_parallel(self, tasks: List[Dict], task_type: str) -> List[bool]:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç —Å–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ (–û–ë–ù–û–í–õ–ï–ù–û –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏)"""
        if not tasks:
            return []
        
        try:
            # –°–æ–∑–¥–∞–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –∑–∞–¥–∞—á–∏ —Å —Ä–∞–∑–±—Ä–æ—Å–æ–º –≤—Ä–µ–º–µ–Ω–∏ –∑–∞–ø—É—Å–∫–∞
            parallel_tasks = []
            delay_range = self.task_delays[task_type]
            
            for i, task in enumerate(tasks):
                # –ó–∞–¥–µ—Ä–∂–∫–∞ —Å—Ç–∞—Ä—Ç–∞ –¥–ª—è —Ä–∞–∑–±—Ä–æ—Å–∞ –Ω–∞–≥—Ä—É–∑–∫–∏
                start_delay = random.uniform(*delay_range) * (i / len(tasks))
                
                parallel_task = asyncio.create_task(
                    self._execute_single_task_with_delay(task, start_delay)
                )
                parallel_tasks.append(parallel_task)
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –≤—Å–µ –∑–∞–¥–∞—á–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
            results = await asyncio.gather(*parallel_tasks, return_exceptions=True)
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            success_count = 0
            error_count = 0
            flood_wait_count = 0
            
            for i, result in enumerate(results):
                task = tasks[i]
                phone = task.get('phone', 'unknown')
                channel = task.get('channel', 'unknown')
                
                if isinstance(result, Exception):
                    error_count += 1
                    if 'FloodWait' in str(result):
                        flood_wait_count += 1
                    logger.error(f"üí• {task_type} | {phone} | @{channel} | {result}")
                elif result:
                    success_count += 1
                    logger.debug(f"‚úÖ {task_type} | {phone} | @{channel}")
                else:
                    error_count += 1
                    logger.warning(f"‚ùå {task_type} | {phone} | @{channel}")
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫–∏ (–û–ë–ù–û–í–õ–ï–ù–û)
            self.performance_stats['processed_tasks'] += len(results)
            self.performance_stats['success_count'] += success_count
            self.performance_stats['error_count'] += error_count
            
            # –ù–û–í–û–ï: –û–±–Ω–æ–≤–ª—è–µ–º –æ–±—â–∏–π —Å—á–µ—Ç—á–∏–∫ –∏ —Å—á–µ—Ç—á–∏–∫–∏ –ø–æ —Ç–∏–ø–∞–º
            self.performance_stats['total_tasks_executed'] += success_count
            self.performance_stats['tasks_this_period'] += success_count
            
            if task_type == 'view':
                self.performance_stats['view_tasks_executed'] += success_count
            elif task_type == 'subscribe':
                self.performance_stats['subscribe_tasks_executed'] += success_count
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
            if self.performance_stats['batches_processed'] > 0:
                self.performance_stats['avg_batch_size'] = (
                    (self.performance_stats['avg_batch_size'] * (self.performance_stats['batches_processed'] - 1) + len(tasks)) 
                    / self.performance_stats['batches_processed']
                )
            
            success_rate = (success_count / len(results)) * 100 if results else 0
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è –ø–æ–¥–ø–∏—Å–æ–∫
            if task_type == 'subscribe' and results:
                logger.info(f"üìä {task_type.upper()} –ë–ê–¢–ß: {success_count}/{len(results)} —É—Å–ø–µ—à–Ω–æ ({success_rate:.1f}%) | FloodWait: {flood_wait_count}")
            else:
                logger.info(f"üìä {task_type.upper()} –ë–ê–¢–ß: {success_count}/{len(results)} —É—Å–ø–µ—à–Ω–æ ({success_rate:.1f}%)")
            
            return [r for r in results if not isinstance(r, Exception)]
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è {task_type}: {e}")
            return []
    
    async def _execute_single_task_with_delay(self, task: Dict, delay: float) -> bool:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –æ–¥–Ω—É –∑–∞–¥–∞—á—É —Å –Ω–∞—á–∞–ª—å–Ω–æ–π –∑–∞–¥–µ—Ä–∂–∫–æ–π"""
        try:
            # –ó–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è —Ä–∞–∑–±—Ä–æ—Å–∞ –Ω–∞–≥—Ä—É–∑–∫–∏
            if delay > 0:
                await asyncio.sleep(delay)
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–¥–∞—á—É
            return await self._execute_task_simple(task)
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á–∏ —Å –∑–∞–¥–µ—Ä–∂–∫–æ–π: {e}")
            return False
    
    async def _execute_task_simple(self, task: Dict) -> bool:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –æ—Ç–¥–µ–ª—å–Ω—É—é –∑–∞–¥–∞—á—É"""
        task_type = task.get('task_type', '')
        session_data = task.get('account_session', '')
        phone = task.get('phone', 'unknown')
        channel = task.get('channel', 'unknown')
        
        if not session_data:
            logger.warning(f"‚ùå {phone}: –Ω–µ—Ç session_data")
            return False
        
        client = None
        
        try:
            # 1. –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç "–Ω–∞ –ª–µ—Ç—É"
            client = TelegramClient(
                StringSession(session_data),
                API_ID, API_HASH,
                lang_code=find_lang_code(task.get('lang', 'English')),
                connection_retries=1,
                timeout=20
            )
            
            # 2. –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è
            await client.connect()
            
            # 3. –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—é
            if not await client.is_user_authorized():
                logger.warning(f"‚ùå {phone}: –Ω–µ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω")
                await self._handle_task_failure(phone, task_type)
                return False
            
            # 4. –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–¥–∞—á—É –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞
            if task_type == 'view':
                success = await self._execute_view_task(client, task)
            elif task_type == 'subscribe':
                success = await self._execute_subscribe_task(client, task)
            else:
                logger.warning(f"‚ùå {phone}: –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –∑–∞–¥–∞—á–∏ {task_type}")
                return False
            
            # 5. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if success:
                await self._handle_task_success(phone)
                return True
            else:
                await self._handle_task_failure(phone, task_type)
                return False
                
        except FloodWaitError as e:
            logger.warning(f"‚è≥ {phone}: FloodWait {e.seconds}s")
            await self._add_to_retry_queue(task, delay=e.seconds)
            return False
            
        except (RPCError, AuthKeyInvalidError) as e:
            logger.warning(f"‚ùå {phone}: –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ - {e}")
            await self._handle_task_failure(phone, task_type)
            return False
            
        except Exception as e:
            logger.error(f"üí• {phone}: –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ - {e}")
            await self._handle_task_failure(phone, task_type)
            return False
            
        finally:
            # 6. –í–°–ï–ì–î–ê –æ—Ç–∫–ª—é—á–∞–µ–º—Å—è
            if client:
                try:
                    await client.disconnect()
                except Exception as e:
                    logger.debug(f"–û—à–∏–±–∫–∞ –æ—Ç–∫–ª—é—á–µ–Ω–∏—è –∫–ª–∏–µ–Ω—Ç–∞ {phone}: {e}")
    
    async def _execute_view_task(self, client: TelegramClient, task: Dict) -> bool:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –∑–∞–¥–∞—á—É –ø—Ä–æ—Å–º–æ—Ç—Ä–∞"""
        channel = task.get('channel', '')
        post_id = task.get('post_id', 0)
        phone = task.get('phone', 'unknown')
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º entity –∫–∞–Ω–∞–ª–∞
            channel_entity = await client.get_entity(channel)
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ—Å–º–æ—Ç—Ä
            await client(GetMessagesViewsRequest(
                peer=channel_entity,
                id=[post_id],
                increment=True
            ))
            
            # –ò–º–∏—Ç–∏—Ä—É–µ–º –≤—Ä–µ–º—è —á—Ç–µ–Ω–∏—è
            reading_time = random.uniform(3, 7)
            await asyncio.sleep(reading_time)
            
            logger.debug(f"‚úÖ {phone}: –ø—Ä–æ—Å–º–æ—Ç—Ä –ø–æ—Å—Ç–∞ {post_id} –≤ @{channel}")
            return True
            
        except Exception as e:
            logger.warning(f"‚ùå {phone}: –æ—à–∏–±–∫–∞ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ @{channel}:{post_id} - {e}")
            return False
    
    async def _execute_subscribe_task(self, client: TelegramClient, task: Dict) -> bool:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –∑–∞–¥–∞—á—É –ø–æ–¥–ø–∏—Å–∫–∏"""
        channel = task.get('channel', '')
        phone = task.get('phone', 'unknown')
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º entity –∫–∞–Ω–∞–ª–∞
            channel_entity = await client.get_entity(channel)
            
            # –õ–æ–≥–∏—Ä—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
            created_at = task.get('created_at', 0)
            execute_at = task.get('execute_at', 0)
            current_time = time.time()
            
            if created_at and execute_at:
                planned_delay = (execute_at - created_at) / 60
                actual_delay = (current_time - created_at) / 60
                execution_drift = (current_time - execute_at) / 60
                
                if abs(execution_drift) <= 2.0:
                    timing_status = "‚è∞ –¢–û–ß–ù–û"
                elif execution_drift < 0:
                    timing_status = f"üöÄ –†–ê–ù–û ({abs(execution_drift):.1f}–º–∏–Ω)"
                else:
                    timing_status = f"‚è≥ –ü–û–ó–î–ù–û (+{execution_drift:.1f}–º–∏–Ω)"
                
                logger.info(f"üì∫ {phone} ‚Üí @{channel} | –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–ª–æ—Å—å: {planned_delay:.1f}–º–∏–Ω | –§–∞–∫—Ç: {actual_delay:.1f}–º–∏–Ω | {timing_status}")
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–¥–ø–∏—Å–∫—É
            await client(JoinChannelRequest(channel_entity))
            
            # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –ø–æ—Å–ª–µ –ø–æ–¥–ø–∏—Å–∫–∏
            await asyncio.sleep(random.uniform(2, 5))
            
            logger.info(f"‚úÖ {phone}: –ø–æ–¥–ø–∏—Å–∞–Ω –Ω–∞ @{channel}")
            return True
            
        except Exception as e:
            logger.warning(f"‚ùå {phone}: –æ—à–∏–±–∫–∞ –ø–æ–¥–ø–∏—Å–∫–∏ –Ω–∞ @{channel} - {e}")
            return False
    
    async def _handle_task_success(self, phone: str):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —É—Å–ø–µ—à–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏"""
        try:
            await reset_account_fails(phone)
            logger.debug(f"üîì {phone}: —Å–±—Ä–æ—à–µ–Ω —Å—á–µ—Ç—á–∏–∫ –æ—à–∏–±–æ–∫")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —É—Å–ø–µ—Ö–∞ –¥–ª—è {phone}: {e}")
    
    async def _handle_task_failure(self, phone: str, task_type: str):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–µ—É–¥–∞—á–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏"""
        try:
            fail_count = await increment_account_fails(phone)
            
            if fail_count >= 3:
                await update_account_status(phone, 'ban')
                logger.warning(f"üö´ {phone}: –ø–µ—Ä–µ–≤–µ–¥–µ–Ω –≤ BAN (–Ω–µ—É–¥–∞—á: {fail_count})")
            else:
                logger.debug(f"‚ö†Ô∏è {phone}: –Ω–µ—É–¥–∞—á–∞ {fail_count}/3 ({task_type})")
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–µ—É–¥–∞—á–∏ –¥–ª—è {phone}: {e}")
    
    async def _add_to_retry_queue(self, task: Dict, delay: int = 0):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –∑–∞–¥–∞—á—É –≤ –æ—á–µ—Ä–µ–¥—å –ø–æ–≤—Ç–æ—Ä–æ–≤"""
        try:
            task['retry_count'] = task.get('retry_count', 0) + 1
            task['retry_after'] = time.time() + delay + random.uniform(60, 300)
            
            if task['retry_count'] <= self.max_retries:
                self.redis_client.lpush('retry_tasks', json.dumps(task))
                logger.debug(f"üîÑ –ó–∞–¥–∞—á–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤ retry (–ø–æ–ø—ã—Ç–∫–∞ {task['retry_count']}/{self.max_retries})")
            else:
                logger.warning(f"‚ùå –ó–∞–¥–∞—á–∞ –æ—Ç–±—Ä–æ—à–µ–Ω–∞ –ø–æ—Å–ª–µ {self.max_retries} –ø–æ–ø—ã—Ç–æ–∫")
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ retry: {e}")
    
    async def _process_retry_tasks(self):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–∞–¥–∞—á–∏ –∏–∑ –æ—á–µ—Ä–µ–¥–∏ –ø–æ–≤—Ç–æ—Ä–æ–≤"""
        try:
            current_time = time.time()
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–æ 10 retry –∑–∞–¥–∞—á –∑–∞ —Ä–∞–∑
            for _ in range(10):
                task_data = self.redis_client.rpop('retry_tasks')
                if not task_data:
                    break
                
                try:
                    task = json.loads(task_data)
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ä–µ–º—è –ø–æ–≤—Ç–æ—Ä–∞
                    if task.get('retry_after', 0) <= current_time:
                        # –í—Ä–µ–º—è –ø—Ä–∏—à–ª–æ - –≤—ã–ø–æ–ª–Ω—è–µ–º
                        success = await self._execute_task_simple(task)
                        if success:
                            logger.debug(f"‚úÖ Retry –∑–∞–¥–∞—á–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
                    else:
                        # –í—Ä–µ–º—è –µ—â–µ –Ω–µ –ø—Ä–∏—à–ª–æ - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≤ –æ—á–µ—Ä–µ–¥—å
                        self.redis_client.lpush('retry_tasks', task_data)
                        break
                        
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ retry: {e}")
                    continue
                    
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ retry –æ—á–µ—Ä–µ–¥–∏: {e}")
    
    async def _process_worker_commands(self):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∫–æ–º–∞–Ω–¥—ã –æ—Ç –±–æ—Ç–∞"""
        try:
            command_data = self.redis_client.rpop('worker_commands')
            if not command_data:
                return
                
            command = json.loads(command_data)
            
            if command['command'] == 'reload_settings':
                logger.info("üîÑ –ü–æ–ª—É—á–µ–Ω–∞ –∫–æ–º–∞–Ω–¥–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫")
                await self._update_cached_settings()
                logger.info("‚úÖ –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±–Ω–æ–≤–ª–µ–Ω—ã")
            elif command['command'] == 'get_stats':
                logger.info("üìä –ó–∞–ø—Ä–æ—Å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –æ—Ç –∞–¥–º–∏–Ω –ø–∞–Ω–µ–ª–∏")
                await self._save_stats_to_redis()  # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            elif command['command'] == 'cleanup_tasks':
                logger.info("üóëÔ∏è –ó–∞–ø—Ä–æ—Å –æ—á–∏—Å—Ç–∫–∏ —Å—Ç–∞—Ä—ã—Ö –∑–∞–¥–∞—á")
                await self._cleanup_old_tasks()
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–æ–º–∞–Ω–¥: {e}")
    
    async def _check_banned_accounts_for_retry(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∑–∞–±–∞–Ω–µ–Ω–Ω—ã–µ –∞–∫–∫–∞—É–Ω—Ç—ã —Ä–∞–∑ –≤ 120 —á–∞—Å–æ–≤"""
        try:
            ban_accounts = await get_ban_accounts_for_retry()
            
            if not ban_accounts:
                logger.info("üîç –ù–µ—Ç –∑–∞–±–∞–Ω–µ–Ω–Ω—ã—Ö –∞–∫–∫–∞—É–Ω—Ç–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏")
                return
            
            logger.info(f"üîç –ü—Ä–æ–≤–µ—Ä—è—é {len(ban_accounts)} –∑–∞–±–∞–Ω–µ–Ω–Ω—ã—Ö –∞–∫–∫–∞—É–Ω—Ç–æ–≤...")
            
            for account in ban_accounts[:5]:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ –±–æ–ª–µ–µ 5 –∑–∞ —Ä–∞–∑
                phone = account['phone_number']
                
                try:
                    # –û—Ç–º–µ—á–∞–µ–º –ø–æ–ø—ã—Ç–∫—É –ø—Ä–æ–≤–µ—Ä–∫–∏
                    await mark_account_retry_attempt(phone)
                    
                    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—É—é –∑–∞–¥–∞—á—É –ø–æ–¥–ø–∏—Å–∫–∏
                    test_task = {
                        'account_session': account['session_data'],
                        'phone': phone,
                        'channel': 'telegram',  # –¢–µ—Å—Ç–æ–≤—ã–π –∫–∞–Ω–∞–ª
                        'lang': account['lang'],
                        'task_type': 'subscribe'
                    }
                    
                    # –ü—ã—Ç–∞–µ–º—Å—è –≤—ã–ø–æ–ª–Ω–∏—Ç—å —Ç–µ—Å—Ç–æ–≤—É—é –∑–∞–¥–∞—á—É
                    success = await self._execute_task_simple(test_task)
                    
                    if success:
                        logger.info(f"üîì {phone}: –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏–∑ –±–∞–Ω–∞!")
                    else:
                        logger.info(f"üö´ {phone}: –æ—Å—Ç–∞–µ—Ç—Å—è –≤ –±–∞–Ω–µ")
                        
                    # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏
                    await asyncio.sleep(random.uniform(30, 60))
                    
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∑–∞–±–∞–Ω–µ–Ω–Ω–æ–≥–æ –∞–∫–∫–∞—É–Ω—Ç–∞ {phone}: {e}")
                    
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∑–∞–±–∞–Ω–µ–Ω–Ω—ã—Ö –∞–∫–∫–∞—É–Ω—Ç–æ–≤: {e}")
    
    async def _cleanup_old_tasks(self):
        """–û—á–∏—â–∞–µ—Ç —Å—Ç–∞—Ä—ã–µ –∑–∞–¥–∞—á–∏ –∏–∑ Redis"""
        try:
            current_time = time.time()
            cutoff_time = current_time - (48 * 3600)  # 48 —á–∞—Å–æ–≤ –Ω–∞–∑–∞–¥
            
            # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –∑–∞–¥–∞—á–∏ –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–π –æ—á–µ—Ä–µ–¥–∏
            old_tasks = self.redis_client.zrangebyscore(
                "task_queue", 0, cutoff_time, start=0, num=1000
            )
            
            if old_tasks:
                for task_json in old_tasks:
                    self.redis_client.zrem("task_queue", task_json)
                    
                logger.info(f"üóëÔ∏è –û—á–∏—â–µ–Ω–æ {len(old_tasks)} —Å—Ç–∞—Ä—ã—Ö –∑–∞–¥–∞—á –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–π –æ—á–µ—Ä–µ–¥–∏")
            
            # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ retry –∑–∞–¥–∞—á–∏
            retry_tasks = self.redis_client.lrange('retry_tasks', 0, -1)
            cleaned_retry = 0
            
            for task_json in retry_tasks:
                try:
                    task = json.loads(task_json)
                    if task.get('created_at', 0) < cutoff_time:
                        self.redis_client.lrem('retry_tasks', 1, task_json)
                        cleaned_retry += 1
                except:
                    # –£–¥–∞–ª—è–µ–º –±–∏—Ç—ã–µ –∑–∞–¥–∞—á–∏
                    self.redis_client.lrem('retry_tasks', 1, task_json)
                    cleaned_retry += 1
            
            if cleaned_retry > 0:
                logger.info(f"üóëÔ∏è –û—á–∏—â–µ–Ω–æ {cleaned_retry} —Å—Ç–∞—Ä—ã—Ö retry –∑–∞–¥–∞—á")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ —Å—Ç–∞—Ä—ã—Ö –∑–∞–¥–∞—á: {e}")
    
    def _reset_performance_counters(self):
        """–°–±—Ä–∞—Å—ã–≤–∞–µ—Ç —Å—á–µ—Ç—á–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∑–∞ –ø–µ—Ä–∏–æ–¥"""
        self.performance_stats['processed_tasks'] = 0
        self.performance_stats['success_count'] = 0
        self.performance_stats['error_count'] = 0
        # –ù–ï —Å–±—Ä–∞—Å—ã–≤–∞–µ–º –æ–±—â–∏–µ —Å—á–µ—Ç—á–∏–∫–∏ total_tasks_executed –∏ —Å—á–µ—Ç—á–∏–∫–∏ –ø–æ —Ç–∏–ø–∞–º
    
    async def _log_enhanced_performance_stats(self):
        """–õ–æ–≥–∏—Ä—É–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        try:
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ Redis –æ—á–µ—Ä–µ–¥–∏
            total_in_redis = self.redis_client.zcard("task_queue") or 0
            retry_count = self.redis_client.llen("retry_tasks") or 0
            current_time = time.time()
            ready_in_redis = self.redis_client.zcount("task_queue", 0, current_time) or 0
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –Ω–∞ –±—É–¥—É—â–µ–µ
            ready_next_minute = self.redis_client.zcount("task_queue", current_time, current_time + 60) or 0
            ready_next_hour = self.redis_client.zcount("task_queue", current_time, current_time + 3600) or 0
            
            # –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
            total_processed = self.performance_stats['processed_tasks']
            tasks_per_min = total_processed / 5 if total_processed > 0 else 0
            success_rate = (self.performance_stats['success_count'] / total_processed * 100) if total_processed > 0 else 0
            
            # –ë–∞—Ç—á —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            avg_batch_time = sum(self.performance_stats['last_batch_times']) / len(self.performance_stats['last_batch_times']) if self.performance_stats['last_batch_times'] else 0
            batches_processed = self.performance_stats['batches_processed']
            avg_batch_size = self.performance_stats['avg_batch_size']
            
            # –í—Ä–µ–º–µ–Ω–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            tasks_last_minute_total = sum(self.performance_stats['tasks_per_second'])
            tasks_last_hour_total = sum(self.performance_stats['tasks_last_minute'])
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º –∑–∞–¥–∞—á
            view_tasks = self.performance_stats['view_tasks_executed']
            subscribe_tasks = self.performance_stats['subscribe_tasks_executed']
            total_execution_time = self.performance_stats['total_execution_time']
            
            # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            uptime = current_time - self.performance_stats['start_time']
            total_executed = self.performance_stats['total_tasks_executed']
            avg_per_minute = (total_executed / (uptime / 60)) if uptime > 60 else 0
            
            # –°—Ç–∞—Ç—É—Å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
            if tasks_per_min > 15 and success_rate > 80:
                performance_status = "üöÄ –û–¢–õ–ò–ß–ù–û"
            elif tasks_per_min > 8 and success_rate > 70:
                performance_status = "‚úÖ –•–û–†–û–®–û"
            elif tasks_per_min > 3 and success_rate > 50:
                performance_status = "‚ö†Ô∏è –°–†–ï–î–ù–ï"
            else:
                performance_status = "‚ùå –ù–ò–ó–ö–û"
            
            logger.info(f"""
üìä –†–ê–°–®–ò–†–ï–ù–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò (5 –º–∏–Ω):
   
   üéØ –í–´–ü–û–õ–ù–ï–ù–ò–ï –ó–ê –ü–ï–†–ò–û–î:
   ‚úÖ –í—ã–ø–æ–ª–Ω–µ–Ω–æ –∑–∞–¥–∞—á: {total_processed} ({tasks_per_min:.1f}/–º–∏–Ω)
   üìà –£—Å–ø–µ—à–Ω–æ—Å—Ç—å: {success_rate:.1f}% ({self.performance_stats['success_count']}/{total_processed})
   ‚ùå –û—à–∏–±–æ–∫: {self.performance_stats['error_count']}
   
   üéØ –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:
   üèÜ –í—Å–µ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ: {total_executed} –∑–∞–¥–∞—á
   ‚è∞ –í—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã: {uptime/3600:.1f} —á–∞—Å–æ–≤
   üìà –°—Ä–µ–¥–Ω—è—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {avg_per_minute:.1f} –∑–∞–¥–∞—á/–º–∏–Ω
   
   üì¶ –ë–ê–¢–ß–ò:
   üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –±–∞—Ç—á–µ–π: {batches_processed}
   üìè –°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {avg_batch_size:.1f}
   ‚è±Ô∏è –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –±–∞—Ç—á–∞: {avg_batch_time:.1f}—Å
   üïê –û–±—â–µ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {total_execution_time:.1f}—Å
   
   üìà –ü–û –¢–ò–ü–ê–ú –ó–ê–î–ê–ß:
   üëÄ –í—Å–µ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤: {view_tasks}
   üì∫ –í—Å–µ–≥–æ –ø–æ–¥–ø–∏—Å–æ–∫: {subscribe_tasks}
   
   üìà –í–†–ï–ú–ï–ù–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:
   ‚è∞ –ó–∞–¥–∞—á –∑–∞ —Ç–µ–∫—É—â—É—é –º–∏–Ω—É—Ç—É: {tasks_last_minute_total}
   üïê –ó–∞–¥–∞—á –∑–∞ —Ç–µ–∫—É—â–∏–π —á–∞—Å: {tasks_last_hour_total}
   
   üì¶ –û–ß–ï–†–ï–î–¨ REDIS:
   üìã –í—Å–µ–≥–æ –∑–∞–¥–∞—á: {total_in_redis}
   ‚úÖ –ì–æ—Ç–æ–≤—ã—Ö —Å–µ–π—á–∞—Å: {ready_in_redis}
   ‚è∞ –ì–æ—Ç–æ–≤—ã—Ö –∑–∞ –º–∏–Ω—É—Ç—É: {ready_next_minute}
   üïê –ì–æ—Ç–æ–≤—ã—Ö –∑–∞ —á–∞—Å: {ready_next_hour}
   üîÑ Retry –∑–∞–¥–∞—á: {retry_count}
   
   üöÄ –û–ë–©–ò–ô –°–¢–ê–¢–£–°: {performance_status}""")
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
    
    async def get_enhanced_task_stats(self) -> Dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∑–∞–¥–∞—á –¥–ª—è –≤–Ω–µ—à–Ω–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
        try:
            current_time = time.time()
            
            total_tasks = self.redis_client.zcard("task_queue") or 0
            ready_tasks = self.redis_client.zcount("task_queue", 0, current_time) or 0
            retry_tasks = self.redis_client.llen("retry_tasks") or 0
            
            # –ì–æ—Ç–æ–≤—ã–µ –∑–∞–¥–∞—á–∏ –Ω–∞ –±–ª–∏–∂–∞–π—à–∏–µ –ø–µ—Ä–∏–æ–¥—ã
            ready_next_minute = self.redis_client.zcount("task_queue", current_time, current_time + 60) or 0
            ready_next_hour = self.redis_client.zcount("task_queue", current_time, current_time + 3600) or 0
            
            # –í—Ä–µ–º–µ–Ω–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            tasks_last_minute = sum(self.performance_stats['tasks_per_second'])
            tasks_last_hour = sum(self.performance_stats['tasks_last_minute'])
            
            # –ë–∞—Ç—á —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            avg_batch_time = sum(self.performance_stats['last_batch_times']) / len(self.performance_stats['last_batch_times']) if self.performance_stats['last_batch_times'] else 0
            
            # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            uptime = current_time - self.performance_stats['start_time']
            total_executed = self.performance_stats['total_tasks_executed']
            avg_per_minute = (total_executed / (uptime / 60)) if uptime > 60 else 0
            avg_per_second = (total_executed / uptime) if uptime > 0 else 0
            
            return {
                'total_tasks': total_tasks,
                'ready_tasks': ready_tasks,
                'future_tasks': total_tasks - ready_tasks,
                'retry_tasks': retry_tasks,
                'processed_last_period': self.performance_stats['processed_tasks'],
                'success_rate': (self.performance_stats['success_count'] / max(self.performance_stats['processed_tasks'], 1)) * 100,
                
                # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
                'ready_tasks_minute': ready_next_minute,
                'ready_tasks_hour': ready_next_hour,
                'tasks_last_minute': tasks_last_minute,
                'tasks_last_5min': self.performance_stats['tasks_this_period'],
                'tasks_last_hour': tasks_last_hour,
                
                # –°—Ä–µ–¥–Ω–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏
                'avg_tasks_per_minute': avg_per_minute,
                'avg_tasks_per_second': avg_per_second,
                
                # –ë–∞—Ç—á –º–µ—Ç—Ä–∏–∫–∏
                'batches_processed': self.performance_stats['batches_processed'],
                'avg_batch_size': self.performance_stats['avg_batch_size'],
                'avg_batch_time': avg_batch_time,
                
                # –ó–∞–¥–∞—á–∏ –ø–æ —Ç–∏–ø–∞–º
                'view_tasks_executed': self.performance_stats['view_tasks_executed'],
                'subscribe_tasks_executed': self.performance_stats['subscribe_tasks_executed'],
                'total_tasks_executed': total_executed,
                
                # –ù–∞—Å—Ç—Ä–æ–π–∫–∏
                'view_batch_size': self.cached_settings.get('view_batch_size', 100),
                'view_batch_delay': self.cached_settings.get('view_batch_delay', 30),
                'subscribe_batch_delay': self.cached_settings.get('subscribe_batch_delay', 60),
                
                # –í—Ä–µ–º—è
                'timestamp': current_time,
                'uptime': uptime
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∑–∞–¥–∞—á: {e}")
            return {}
    
    async def stop(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤–æ—Ä–∫–µ—Ä–∞"""
        logger.info("‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–∫–∞ enhanced –≤–æ—Ä–∫–µ—Ä–∞...")
        self.running = False
    
    async def _shutdown(self):
        """–ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã"""
        logger.info("üîÑ –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã enhanced –≤–æ—Ä–∫–µ—Ä–∞...")
        
        try:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            await self._save_stats_to_redis()
            
            # –õ–æ–≥–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            total_uptime = time.time() - self.performance_stats['start_time']
            total_processed = self.performance_stats['total_tasks_executed']
            
            logger.info(f"""
üìä –§–ò–ù–ê–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –í–û–†–ö–ï–†–ê:
   ‚è∞ –í—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã: {total_uptime/3600:.1f} —á–∞—Å–æ–≤
   ‚úÖ –í—Å–µ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ –∑–∞–¥–∞—á: {total_processed}
   üëÄ –ü—Ä–æ—Å–º–æ—Ç—Ä–æ–≤: {self.performance_stats['view_tasks_executed']}
   üì∫ –ü–æ–¥–ø–∏—Å–æ–∫: {self.performance_stats['subscribe_tasks_executed']}
   üì¶ –ë–∞—Ç—á–µ–π –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {self.performance_stats['batches_processed']}
   üöÄ –°—Ä–µ–¥–Ω—è—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {total_processed/(total_uptime/3600):.1f} –∑–∞–¥–∞—á/—á–∞—Å
            """)
            
            # –ó–∞–∫—Ä—ã–≤–∞–µ–º Redis
            if self.redis_client:
                self.redis_client.close()
            
            # –ó–∞–∫—Ä—ã–≤–∞–µ–º –ë–î
            await shutdown_db_pool()
            
            logger.info("‚úÖ Enhanced –≤–æ—Ä–∫–µ—Ä –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏: {e}")

# –ê–ª–∏–∞—Å –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
SimpleTaskWorker = EnhancedTaskWorker

# –ó–∞–ø—É—Å–∫ –≤–æ—Ä–∫–µ—Ä–∞
async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –≤–æ—Ä–∫–µ—Ä–∞"""
    worker = EnhancedTaskWorker()
    
    try:
        await worker.start()
    except KeyboardInterrupt:
        logger.info("‚èπÔ∏è –ü–æ–ª—É—á–µ–Ω Ctrl+C, –∑–∞–≤–µ—Ä—à–∞–µ–º —Ä–∞–±–æ—Ç—É...")
    except Exception as e:
        logger.error(f"üí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
    finally:
        await worker.stop()

if __name__ == "__main__":
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º uvloop –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
    try:
        import uvloop
        uvloop.install()
        logger.info("‚úÖ uvloop —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
    except ImportError:
        logger.info("‚ö†Ô∏è uvloop –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π event loop")
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –≤–æ—Ä–∫–µ—Ä
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ Enhanced Task Worker —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π...")
    asyncio.run(main())